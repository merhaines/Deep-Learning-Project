{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ckgpeHzuLojvtnu2lh6X6MjYoNEkxaXs",
      "authorship_tag": "ABX9TyMkjmHH5qlfUd5sA00zybaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merhaines/Deep-Learning-Project/blob/main/icepredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Data"
      ],
      "metadata": {
        "id": "t1P054J8Tqi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is found at https://nsidc.org/data/g10010/versions/2#anchor-1. The dataset consists of ice concentration data for each pixel in a 240 x 1140 grid of the Arctic. Ice concentration is between 0-100, and land pixels are set to 120. For the purpose of this analysis, any concentration greater than or equal to 15 is considered a pixel covered with sea ice, and any pixel with a concentration less than 15 is considered open water."
      ],
      "metadata": {
        "id": "X4QFJTNldok2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To download the data**, go to our github repository and download the folder [G10010_SIBT1850_V2](https://github.com/merhaines/Deep-Learning-Project/tree/main/G10010_SIBT1850_V2)"
      ],
      "metadata": {
        "id": "--F8e2zcTOd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "CPXyF9xrUiX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install netcdf4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4mspTgExLEt",
        "outputId": "9bb95f1e-6f34-4400-fb65-68e039bd3b9f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting netcdf4\n",
            "  Downloading netCDF4-1.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netcdf4) (1.22.4)\n",
            "Collecting cftime\n",
            "  Downloading cftime-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netcdf4\n",
            "Successfully installed cftime-1.6.2 netcdf4-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import netCDF4 as nc\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPooling1D, Flatten, Dense\n"
      ],
      "metadata": {
        "id": "R1N3Ymm1w4JC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "UQyAlKq6Twip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive and access dataset\n",
        "fp = '/content/drive/MyDrive/sea ice predictor/G10010_SIBT1850_V2/G10010_sibt1850_v2.0.nc' # where folder is saved in drive\n",
        "ds = nc.Dataset(fp)\n",
        "siconc = ds['seaice_conc'] "
      ],
      "metadata": {
        "id": "DhuTNDUNxqWO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab months\n",
        "n_months_in_dataset = len(siconc[:])\n",
        "n_rows = len(siconc[1, :])\n",
        "n_cols = len(siconc[1, 1, :])\n",
        "forecast = 3; # 3 month forecast\n",
        "n_months_input = 3*12;\n",
        "\n",
        "X_input = siconc[(n_months_in_dataset - n_months_input - forecast):-forecast]\n",
        "Y_input = siconc[(n_months_in_dataset - n_months_input): ]\n",
        "\n",
        "# set land pixels to 0\n",
        "X_input[X_input == 120] = 0\n",
        "Y_input[Y_input == 120] = 0\n",
        "\n",
        "# normalize\n",
        "X_input = X_input/100\n",
        "Y_input = Y_input/100\n",
        "\n",
        "# make Y_labels 0 (water) or 1 (ice)\n",
        "Y_input[Y_input < 0.15] = 0.0\n",
        "Y_input[Y_input >= 0.15] = 1.0\n",
        "\n",
        "X_input = X_input.data\n",
        "Y_input = Y_input.data\n",
        "Y_input = Y_input.astype(int)\n",
        "\n",
        "# convert Y_labels to 1D matrix\n",
        "Y_input = Y_input.reshape(36, 240*1440)\n"
      ],
      "metadata": {
        "id": "BhomJMdoYCUt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into training and test data\n",
        "X_train = X_input[0:30, :, :]\n",
        "Y_train = Y_input[0:30]\n",
        "\n",
        "X_test = X_input[40:, :, :]\n",
        "Y_test = Y_input[40:]\n",
        "\n",
        "X_val = X_input[30:40, :, :]\n",
        "Y_val = Y_input[30:40]"
      ],
      "metadata": {
        "id": "Ao_ya6hcuLVk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "cY6dH3z-VC_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the actual neural net\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(240,1440,1)))\n",
        "\n",
        "# Add a max pooling layer with 2x2 pool size\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add another convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation\n",
        "model.add(Conv2D(2, (3,3), activation='relu'))\n",
        "\n",
        "# Add another max pooling layer with 2x2 pool size\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add a flatten layer to convert the 2D output from the convolutional layers into a 1D feature vector\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 units and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add an output layer with a single unit and sigmoid activation for binary classification\n",
        "model.add(Dense(units = 240*1440, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ZWo1XoDTChq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb12bb4-940d-4292-a4b0-3be92618a8b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 238, 1438, 32)     320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 119, 719, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 117, 717, 2)       578       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 58, 358, 2)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 41528)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               5315712   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 345600)            44582400  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,899,010\n",
            "Trainable params: 49,899,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "eA2yvgNFVGRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "history = model.fit(X_train, Y_train, epochs=30, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "bai2Y7q3DEXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec79877f-590b-440f-90a9-2e41cf5b2295"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6931 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6927 - accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.6889 - accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.6685 - accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.6063 - accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.4824 - accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.3111 - accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.1625 - accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0992 - accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.0905 - accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0918 - accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0917 - accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.0908 - accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0895 - accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.0880 - accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0863 - accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.0842 - accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.0816 - accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.0820 - accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.0804 - accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.0774 - accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.0752 - accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.0755 - accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.0763 - accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.0745 - accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0730 - accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.0726 - accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0727 - accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0716 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_val, Y_val)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQLyl3p_johp",
        "outputId": "cc99972c-8b58-40e2-8645-c6ee979f8e0e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 304ms/step - loss: 0.1395 - accuracy: 0.0000e+00\n",
            "Test accuracy: 0.0\n"
          ]
        }
      ]
    }
  ]
}